# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B_1EGtMPf4ZgpH61rnaiy0rlGGWR5UZr
"""

from tensorflow.keras.datasets.cifar10 import load_data
(x_train , y_train), (x_test, y_test) = load_data()

print(x_train.shape)
print(x_test.shape)

trans = [
  "airplane",
  "automobile",						
  "bird",
  "cat",
  "deer",
  "dog",				
  "frog",
  "horse",
  "ship",
  "truck",
]

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
idx = 222
print(trans[y_train[idx][0]])
plt.imshow(x_train[idx])
# idx = 0
# print(y_train[idx])
# plt.imshow(x_train[idx])

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Dense, Flatten , Dropout

layers =[
    # (3*3*3)27 (1 filter) * 64 + 64 (bias) =1792
    Conv2D(64, kernel_size=3, padding="same",activation="relu", input_shape=(32,32,3)),
    MaxPooling2D(),
    # 576 (1 filter) * 128 + 128 (bias) = 72856
    Conv2D(128, kernel_size=3,padding="same",activation="relu"),
    MaxPooling2D(),
    Conv2D(256, kernel_size=3,padding="same",activation="relu"),
    MaxPooling2D(),
    Conv2D(512, kernel_size=3,padding="same",activation="relu"),
    MaxPooling2D(),
    Flatten(),
    # 
    Dense(256 , activation="relu"),
    # 隨機丟棄 1/4 , 訓練 3/4
    Dropout(0.25),
    Dense(10,activation="softmax")
]
model = Sequential(layers)
model.summary()

from tensorflow.keras.losses import SparseCategoricalCrossentropy # 省ram空間, 避免 one hot in coding
model.compile(loss=SparseCategoricalCrossentropy(),
              optimizer="adam",
              metrics=["accuracy"])

x_train_norm = x_train / 255
x_test_norm = x_test / 255

# validation_split: 留下一些訓練資料來看模型好不好
# batch_size: 看多少筆做一次平均梯度
# epochs : 整份資料看幾遍
# verboes: log的詳細程度[1:進度條 0:空無一度 2:必要的就好]
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
c = [
     ModelCheckpoint("cnn.h5",save_best_only=True),
     EarlyStopping(patience=3, restore_best_weights=True)
]
model.fit(x_train_norm,
          # space
          y_train,
          validation_split=0.1,
          batch_size=200,
          epochs=50,
          verbose=2,
          callbacks=c)

model.evaluate(x_test_norm, y_test)

pre = model.predict_classes(x_test_norm)
pre

# pre, y_test shape
print(y_test.shape)
print(pre.shape)
y_test_reshape = y_test.reshape(-1)
print(y_test_reshape.shape)

import numpy as np
# 抓出非0的位置
idx = np.nonzero(pre != y_test_reshape)[0]
idx = idx[:200]
false_label = y_test_reshape[idx]  
false_pred = pre[idx] # 預測錯誤的正確答案
false_img = x_test[idx]

#plt.figure(figsize=(14, 42))
plt.figure(figsize=(20, 60))
width = 10
height = len(idx)  // width +1 # 取商, +1 多一列取餘數
for i, img in enumerate(false_img) :
  plt.subplot(height, width, i+1)
  t = "[True]:{}\n[Pred]:{}".format(trans[false_label[i]],
                                    trans[false_pred[i]])
  plt.title(t)
  plt.axis("off")
  plt.imshow(img)